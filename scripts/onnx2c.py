#!/usr/bin/env python3

import os
import argparse
import torch
import onnx
import onnxruntime

from enum import Enum, unique

SHAPE_DIMENSION = 4

@unique
class InputType(Enum):
    NEG_ONE = 0
    ONE = 1
    INCREMENT = 2  # from 0~n
    RANDOM = 3

comment_info = '''//-*-c-*-

//=============================================================================
//
// Copyright (c) Ant Group Co., Ltd
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
//
//=============================================================================

// This file should be auto generated by onnx2c.py,
// it's used as driver for testing ONNX.
'''

include_header_stmt = '''
#include <math.h>
#include <stdlib.h>
#include <stdbool.h>
#include <stdio.h>

#include "common/rtlib.h"
'''

gid_stmt = '''
/**
* @brief generate input data for testing ONNX
*
*
* @param n
* @param c
* @param h
* @param w
* @param data, data pointer
* @return TENSOR input data
*/
TENSOR *Generate_input_data(size_t n, size_t c, size_t h, size_t w, double *data) {
    return Alloc_tensor(n, c, h, w, data);
}
'''

# Updated validation functions that can handle any number of result arrays
vod_stmt = r'''
/**
 * @brief Validate multiple output vectors against expected vectors using absolute error.
 *
 * @param results An array of pointers to double arrays (result arrays).
 * @param num_results The number of result arrays.
 * @param expect An array of expected values of length num_results * len.
 * @param len The length of each result array.
 * @return true if all values match within the absolute error threshold.
 */
bool Validate_output_data_absolute_error(double **results, int num_results, double *expect, int len) {
    bool print_all = false;
    const char* print_all_str = getenv("PRINT_ALL");
    if(print_all_str != NULL) {
        printf("Value of PRINT_ALL: %s\n", print_all_str);
        print_all = true;
    }
    // For testing purposes, force print_all to true
    // Remove or comment out the next line if you want to use the environment variable
    print_all = true;

    const char* absolute_error_str = getenv("ABS_ERROR");
    double absolute_error = 0.0001;
    if(absolute_error_str != NULL) {
        printf("Value of ABS_ERROR: %s\n", absolute_error_str);
        absolute_error = atof(absolute_error_str);
    }
    printf("Expect absolute error less than: %f\n", absolute_error);
    int count = 0;

    for(int k = 0; k < num_results; k++) {
        double *result = results[k];
        int expect_offset = k * len;
        for(int i = 0; i < len; i++) {
            double result_absolute_error = fabs(result[i] - expect[expect_offset + i]);
            if(print_all) {
                printf("Comparison %d - index: %d, result: %f, expect: %f, absolute error=%f, ",
                       k + 1, i, result[i], expect[expect_offset + i], result_absolute_error);
                if(result_absolute_error > absolute_error) {
                    count++;
                    printf("failed (%d)\n", count);
                } else {
                    printf("ok\n");
                }
            } else {
                if(result_absolute_error > absolute_error) {
                    printf("Comparison %d - index: %d, value: %f != %f, absolute error=%f\n",
                           k + 1, i, result[i], expect[expect_offset + i], result_absolute_error);
                    return false;
                }
            }
        }
    }

    if(print_all && (count != 0)) {
        printf("Total failures: %d\n", count);
        return false;
    }
    return true;
}

/**
 * @brief Validate multiple output vectors against expected vectors using relative error.
 *
 * @param results An array of pointers to double arrays (result arrays).
 * @param num_results The number of result arrays.
 * @param expect An array of expected values of length num_results * len.
 * @param len The length of each result array.
 * @return true if all values match within the relative error threshold.
 */
bool Validate_output_data_relative_error(double **results, int num_results, double *expect, int len) {
    bool print_all = false;
    const char* print_all_str = getenv("PRINT_ALL");
    if(print_all_str != NULL) {
        printf("Value of PRINT_ALL: %s\n", print_all_str);
        print_all = true;
    }
    // For testing purposes, force print_all to true
    // Remove or comment out the next line if you want to use the environment variable
    print_all = true;

    const char* relative_error_str = getenv("REL_ERROR");
    double relative_error = 0.001;
    if(relative_error_str != NULL) {
        printf("Value of REL_ERROR: %s\n", relative_error_str);
        relative_error = atof(relative_error_str);
    }
    printf("Expect relative error less than: %f\n", relative_error);
    int count = 0;

    for(int k = 0; k < num_results; k++) {
        double *result = results[k];
        int expect_offset = k * len;
        for(int i = 0; i < len; i++) {
            double expected_value = expect[expect_offset + i];
            double denominator = fabs(expected_value);
            double result_relative_error;
            if(denominator > 1e-10) {
                result_relative_error = fabs(result[i] - expected_value) / denominator;
            } else {
                // If expected value is zero or very small, use absolute error
                result_relative_error = fabs(result[i] - expected_value);
            }

            if(print_all) {
                printf("Comparison %d - index: %d, result: %f, expect: %f, relative error=%f, ",
                       k + 1, i, result[i], expected_value, result_relative_error);
                if(result_relative_error > relative_error) {
                    count++;
                    printf("failed (%d)\n", count);
                } else {
                    printf("ok\n");
                }
            } else {
                if(result_relative_error > relative_error) {
                    printf("Comparison %d - index: %d, value: %f != %f, relative error=%f\n",
                           k + 1, i, result[i], expected_value, result_relative_error);
                    return false;
                }
            }
        }
    }

    if(print_all && (count != 0)) {
        printf("Total failures: %d\n", count);
        return false;
    }
    return true;
}
'''

def get_parser():
    parser = argparse.ArgumentParser(description='generate c program')
    parser.add_argument('--model-path', '-mp', type=str, dest='model_path', required=True, help='Path of onnx file')
    parser.add_argument('--input-all-negone', '-iano', dest='input_all_neg_one', action='store_true', default=False,
                        help='input is all -1, by default is random input value')
    parser.add_argument('--input-all-one', '-iao', dest='input_all_one', action='store_true', required=False,
                        help='input is all 1, by default is random input value')
    parser.add_argument('--input-increment', '-ii', dest='input_increment', action='store_true', required=False,
                        help='input is from 0~n, stride is 1, by default is random input value')
    parser.add_argument('--input-path', '-ip', type=str, dest='input_path', required=False,
                        help='Path of input image, not implemented yet')
    parser.add_argument('--output-path', '-op', type=str, dest='output_path', required=False,
                        help='Path of output file, default is main.c in current path')
    return parser

def write_main_c_program(global_var: str, main_func: str, output_file_path: None):
    assert (len(global_var) != 0)
    assert (len(main_func) != 0)

    if output_file_path is None:
        output_file_path = "main.c"

    with open(output_file_path, "w") as output_file:
        output_file.write(comment_info)
        output_file.write(include_header_stmt)
        output_file.write(global_var)
        output_file.write(gid_stmt)
        output_file.write(vod_stmt)
        output_file.write(main_func)

class InputTensor:
    def __init__(self, name: str, shape: list, data: torch.Tensor):
        self.name = name
        self.shape = shape
        self.data = data

    def flatten_data(self):
        return self.data.flatten().tolist()

    def total_size(self):
        return self.data.numel()

def get_input_data(shape: list, input_type: InputType = InputType.RANDOM):
    if input_type == InputType.NEG_ONE:
        input_data = torch.full(shape, -1.0)
    elif input_type == InputType.ONE:
        input_data = torch.ones(shape)
    elif input_type == InputType.INCREMENT:
        up_val = 1
        for val in shape:
            up_val *= val
        input_data = torch.arange(0, up_val, dtype=torch.float32).reshape(shape)
    else:
        input_data = torch.randn(shape)
    return input_data

def format_input_data_and_get_expected_data(onnx_file_path: str, input_type: InputType = InputType.RANDOM,
                                            input_file_path: str = None):
    # Load onnx file
    onnx_model = onnx.load(onnx_file_path)
    onnx.checker.check_model(onnx_model)

    ort_session = onnxruntime.InferenceSession(onnx_file_path)

    inputs = []
    input_tensors = []
    if input_file_path is None:
        assert (len(ort_session.get_inputs()) > 0)
        for i in range(len(ort_session.get_inputs())):
            input_shape = ort_session.get_inputs()[i].shape  # list
            input_name = ort_session.get_inputs()[i].name
            input_data = get_input_data(input_shape, input_type)
            input_tensor = InputTensor(input_name, input_shape, input_data)
            inputs.append(input_data)
            input_tensors.append(input_tensor)
        assert (len(input_tensors) > 0)
    else:
        # TODO: construct read from file statements
        print("read from input file has not supported yet")

    def to_numpy(tensor):
        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()

    # compute ONNX Runtime output prediction
    ort_inputs = {}
    for i in range(len(ort_session.get_inputs())):
        ort_inputs[ort_session.get_inputs()[i].name] = to_numpy(inputs[i])
    ort_outs = ort_session.run(None, ort_inputs)

    output_tensors = []
    for i in range(len(ort_outs)):
        output_name = ort_session.get_outputs()[i].name
        output_data = torch.from_numpy(ort_outs[i])
        output_shape = list(output_data.shape)
        output_tensor = InputTensor(output_name, output_shape, output_data)
        output_tensors.append(output_tensor)

    return input_tensors, output_tensors

def generate_global_var(expected_outputs: list):
    # Generate global variables for expected data
    expected_data_stmt = ""
    expected_data_len_stmt = ""
    total_expected_data = []
    for idx, output in enumerate(expected_outputs):
        var_name = f"Expected_data_{idx}"
        data_list = output.flatten_data()
        expected_data_stmt += f"\ndouble {var_name}[] = {{"
        expected_data_stmt += ', '.join(map(str, data_list))
        expected_data_stmt += "};\n"
        expected_data_len_stmt += f"int Expected_len_{idx} = {len(data_list)};\n"
        total_expected_data.extend(data_list)
    # Combined expected data for validation functions
    combined_expected_data_stmt = "\ndouble Expected_data[] = {"
    combined_expected_data_stmt += ', '.join(map(str, total_expected_data))
    combined_expected_data_stmt += "};\n"
    combined_expected_data_len_stmt = f"int Expected_len = {len(total_expected_data)};\n"
    return expected_data_stmt + expected_data_len_stmt + combined_expected_data_stmt + combined_expected_data_len_stmt

def generate_main_func(input_tensors: list, output_tensors: list):
    input_var_template = "input_data_{idx}"
    input_array_template = "  double {var_name}[] = {{ {data} }};\n"
    generate_input_template = "  TENSOR *{tensor_name} = Generate_input_data({n}, {c}, {h}, {w}, {var_name});\n"
    printf_template = '  printf("{name}\\n");\n'
    print_tensor_template = '  Print_tensor(stdout, {tensor_name});\n'
    free_tensor_template = '  Free_tensor({tensor_name});\n'
    prepare_context = "  Prepare_context();\n\n"
    prepare_input_template = '  Prepare_input_large({tensor_name}, "{name}");\n'
    run_main_graph = "  Run_main_graph();\n\n"
    finalize_context = "  Finalize_context();\n\n"

    # Collecting results
    result_array_stmt = ""
    result_pointers_stmt = "  double *results[{num_outputs}];\n"
    get_output_template = '  results[{idx}] = Handle_output("{name}");\n'
    free_result_template = '  free(results[{idx}]);\n'

    validate_call_stmt = '''
  bool res_relative = Validate_output_data_relative_error(results, {num_outputs}, Expected_data, {len});
  bool res_absolute = Validate_output_data_absolute_error(results, {num_outputs}, Expected_data, {len});
'''
    success_check_stmt = '''
  if (res_relative || res_absolute) {
    printf("SUCCESS!\\n");
  } else {
    printf("FAILED!\\n");
  }
'''

    return_stmt = "  return 0;\n"

    main_body = prepare_context
    # Input preparation
    for idx, it_item in enumerate(input_tensors):
        input_var_name = input_var_template.format(idx=idx)
        data_list = it_item.flatten_data()
        data_str = ', '.join(map(str, data_list))
        input_array_decl = input_array_template.format(var_name=input_var_name, data=data_str)
        tensor_name = f"tensor_{idx}"
        shape = it_item.shape
        generate_input_stmt = generate_input_template.format(
            tensor_name=tensor_name,
            n=shape[0], c=shape[1] if len(shape) > 1 else 1,
            h=shape[2] if len(shape) > 2 else 1,
            w=shape[3] if len(shape) > 3 else 1,
            var_name=input_var_name
        )
        print_stmt = printf_template.format(name=it_item.name)
        print_tensor_stmt = print_tensor_template.format(tensor_name=tensor_name)
        prepare_input_stmt = prepare_input_template.format(tensor_name=tensor_name, name=it_item.name)
        free_tensor_stmt = free_tensor_template.format(tensor_name=tensor_name)

        main_body += input_array_decl + generate_input_stmt + print_stmt + print_tensor_stmt + prepare_input_stmt + free_tensor_stmt

    main_body += run_main_graph

    # Collect outputs
    num_outputs = len(output_tensors)
    result_pointers_decl = result_pointers_stmt.format(num_outputs=num_outputs)
    main_body += result_pointers_decl
    total_output_len = 0
    for idx, ot_item in enumerate(output_tensors):
        get_output_stmt = get_output_template.format(idx=idx, name=ot_item.name)
        main_body += get_output_stmt
        total_output_len += ot_item.total_size()

    main_body += finalize_context

    validate_stmt = validate_call_stmt.format(num_outputs=num_outputs, len=total_output_len)
    main_body += validate_stmt

    # Free results
    for idx in range(num_outputs):
        main_body += free_result_template.format(idx=idx)

    main_body += success_check_stmt
    main_body += return_stmt

    main_method_template = "\nint main(int argc, char* argv[]) {\n%s\n}\n"

    return main_method_template % main_body

def main():
    parser = get_parser()

    args = parser.parse_args()
    path = os.path.dirname(os.path.realpath(args.model_path))
    if not os.path.exists(path):
        os.makedirs(path, exist_ok=True)
    if args.input_path is None:
        print("Input file path is not provided (not implemented yet), will use random input content.")
    if args.output_path is None:
        print("Output file path is not provided, will output main.c to current path.")

    input_type = InputType.RANDOM
    if args.input_all_neg_one:
        input_type = InputType.NEG_ONE
    elif args.input_all_one:
        input_type = InputType.ONE
    elif args.input_increment:
        input_type = InputType.INCREMENT

    input_tensors, expected_outputs = format_input_data_and_get_expected_data(args.model_path, input_type,
                                                                              args.input_path)
    global_var = generate_global_var(expected_outputs)
    main_func = generate_main_func(input_tensors, expected_outputs)
    write_main_c_program(global_var, main_func, args.output_path)

if __name__ == '__main__':
    main()